{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T06:49:21.689375Z",
     "iopub.status.busy": "2024-12-15T06:49:21.688460Z",
     "iopub.status.idle": "2024-12-15T06:49:22.821222Z",
     "shell.execute_reply": "2024-12-15T06:49:22.820144Z",
     "shell.execute_reply.started": "2024-12-15T06:49:21.689335Z"
    }
   },
   "source": [
    "## Story Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Temporary Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T10:33:24.722318Z",
     "iopub.status.busy": "2025-02-26T10:33:24.722057Z",
     "iopub.status.idle": "2025-02-26T10:33:25.803324Z",
     "shell.execute_reply": "2025-02-26T10:33:25.802184Z",
     "shell.execute_reply.started": "2025-02-26T10:33:24.722291Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/kaggle/working': Device or resource busy\n"
     ]
    }
   ],
   "source": [
    "!rm -r '/kaggle/working'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Story Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T10:33:25.813333Z",
     "iopub.status.busy": "2025-02-26T10:33:25.812919Z",
     "iopub.status.idle": "2025-02-26T10:33:56.020215Z",
     "shell.execute_reply": "2025-02-26T10:33:56.019326Z",
     "shell.execute_reply.started": "2025-02-26T10:33:25.813281Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T10:33:56.021851Z",
     "iopub.status.busy": "2025-02-26T10:33:56.021347Z",
     "iopub.status.idle": "2025-02-26T10:33:56.027855Z",
     "shell.execute_reply": "2025-02-26T10:33:56.026986Z",
     "shell.execute_reply.started": "2025-02-26T10:33:56.021823Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "    # Extract all keyword-story pairs\n",
    "    pattern = re.compile(r'<\\|keywords\\|>(.*?)<\\|story\\|>(.*?)<\\|endoftext\\|>', re.DOTALL)\n",
    "    matches = pattern.findall(data)\n",
    "\n",
    "    data_pairs = []\n",
    "    \n",
    "    i = 0\n",
    "    for keywords, story in matches:\n",
    "        # Format the input text with special tokens\n",
    "        if(i<50000):\n",
    "            formatted_text = f\"<|keywords|> {keywords.strip()} <|story|> {story.strip()} <|endoftext|>\"\n",
    "            data_pairs.append(formatted_text)\n",
    "            i = i+1\n",
    "    return data_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T10:34:03.453212Z",
     "iopub.status.busy": "2025-02-26T10:34:03.452417Z",
     "iopub.status.idle": "2025-02-26T10:35:31.244471Z",
     "shell.execute_reply": "2025-02-26T10:35:31.243680Z",
     "shell.execute_reply.started": "2025-02-26T10:34:03.453177Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adb61136672d4d03a1ecbadff0c656c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f78d0489d9b401d8229bad1b564cf4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a19414afef7a448692cd2f7b716a1e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c798fe410bb64ff1820b39d59f2e9d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa4ddfc0adfa4e83b900d77fc4c9d83b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d56c94a28a25481c9b9615ca702d7b2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9295a96e4b484a008cc4a04081ebdf1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d05f5585de74021a692b74807ef5335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load the GPT-2 tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token # Use EOS token as padding\n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\": [\"<|keywords|>\", \"<|story|>\", \"<|endoftext|>\"]})\n",
    "\n",
    "# Load the GPT-2 model\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Load and preprocess the dataset from the file\n",
    "data_pairs = preprocess_data('/kaggle/input/storydataset2/formatted_text.txt')\n",
    "\n",
    "# Convert it to Hugging Face Dataset format\n",
    "train_dataset = Dataset.from_dict({'text': data_pairs})\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    encoding = tokenizer(\n",
    "        examples['text'], \n",
    "        padding=\"max_length\",  # Ensures uniform length\n",
    "        truncation=True, \n",
    "        max_length=512, \n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    encoding[\"labels\"] = encoding[\"input_ids\"]  # Use input_ids as labels\n",
    "    return encoding\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T10:35:43.149258Z",
     "iopub.status.busy": "2025-02-26T10:35:43.148461Z",
     "iopub.status.idle": "2025-02-26T10:35:45.668420Z",
     "shell.execute_reply": "2025-02-26T10:35:45.667495Z",
     "shell.execute_reply.started": "2025-02-26T10:35:43.149221Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/1741469659.py:23: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, Trainer, TrainingArguments\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "# Split into training and validation\n",
    "tokenized_dataset = train_dataset.train_test_split(test_size=0.1)\n",
    "\n",
    "# 4. Define Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./story_generation_model\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=4,\n",
    "    per_device_train_batch_size=4,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator  # Handles padding during training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T10:36:02.061342Z",
     "iopub.status.busy": "2025-02-26T10:36:02.060510Z",
     "iopub.status.idle": "2025-02-26T17:33:50.609323Z",
     "shell.execute_reply": "2025-02-26T17:33:50.608563Z",
     "shell.execute_reply.started": "2025-02-26T10:36:02.061307Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250226_103636-7l5qxzip</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/praveenksharma-bits-pilani/huggingface/runs/7l5qxzip' target=\"_blank\">./story_generation_model</a></strong> to <a href='https://wandb.ai/praveenksharma-bits-pilani/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/praveenksharma-bits-pilani/huggingface' target=\"_blank\">https://wandb.ai/praveenksharma-bits-pilani/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/praveenksharma-bits-pilani/huggingface/runs/7l5qxzip' target=\"_blank\">https://wandb.ai/praveenksharma-bits-pilani/huggingface/runs/7l5qxzip</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22500' max='22500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22500/22500 6:57:08, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.132600</td>\n",
       "      <td>0.954637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.973300</td>\n",
       "      <td>0.902760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.936800</td>\n",
       "      <td>0.871572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.898700</td>\n",
       "      <td>0.851485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.882400</td>\n",
       "      <td>0.838151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.872200</td>\n",
       "      <td>0.824667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.866200</td>\n",
       "      <td>0.817094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.860200</td>\n",
       "      <td>0.806334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.841300</td>\n",
       "      <td>0.801199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.846200</td>\n",
       "      <td>0.796030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.834600</td>\n",
       "      <td>0.789604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.784809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.802700</td>\n",
       "      <td>0.781095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.800800</td>\n",
       "      <td>0.776482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.797100</td>\n",
       "      <td>0.773010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.796100</td>\n",
       "      <td>0.769971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.791000</td>\n",
       "      <td>0.767817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.790100</td>\n",
       "      <td>0.763032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.789000</td>\n",
       "      <td>0.760832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.782700</td>\n",
       "      <td>0.758465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.781100</td>\n",
       "      <td>0.756241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.772400</td>\n",
       "      <td>0.754292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.756100</td>\n",
       "      <td>0.752879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.766500</td>\n",
       "      <td>0.751216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.752000</td>\n",
       "      <td>0.749748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.759400</td>\n",
       "      <td>0.747286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.757400</td>\n",
       "      <td>0.744838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.749100</td>\n",
       "      <td>0.744885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.748000</td>\n",
       "      <td>0.742915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.756700</td>\n",
       "      <td>0.741091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.746400</td>\n",
       "      <td>0.740169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.755900</td>\n",
       "      <td>0.738213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.757900</td>\n",
       "      <td>0.737192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.740100</td>\n",
       "      <td>0.736876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.743800</td>\n",
       "      <td>0.736129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.737000</td>\n",
       "      <td>0.735323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.729500</td>\n",
       "      <td>0.735424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.736300</td>\n",
       "      <td>0.734284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.739800</td>\n",
       "      <td>0.733557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.731900</td>\n",
       "      <td>0.732569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>0.737100</td>\n",
       "      <td>0.732409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.733800</td>\n",
       "      <td>0.731837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>0.727000</td>\n",
       "      <td>0.731302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.734700</td>\n",
       "      <td>0.730969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>0.727700</td>\n",
       "      <td>0.730968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_gpt2/tokenizer_config.json',\n",
       " './fine_tuned_gpt2/special_tokens_map.json',\n",
       " './fine_tuned_gpt2/vocab.json',\n",
       " './fine_tuned_gpt2/merges.txt',\n",
       " './fine_tuned_gpt2/added_tokens.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tune the model\n",
    "trainer.train()\n",
    "\n",
    "# 7. Save the Model\n",
    "model.save_pretrained(\"./fine_tuned_gpt2\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T18:07:41.934622Z",
     "iopub.status.busy": "2025-02-26T18:07:41.934253Z",
     "iopub.status.idle": "2025-02-26T18:07:42.067774Z",
     "shell.execute_reply": "2025-02-26T18:07:42.066816Z",
     "shell.execute_reply.started": "2025-02-26T18:07:41.934590Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50259, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50259, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model_path = \"./fine_tuned_gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T18:07:45.158507Z",
     "iopub.status.busy": "2025-02-26T18:07:45.158173Z",
     "iopub.status.idle": "2025-02-26T18:07:45.165269Z",
     "shell.execute_reply": "2025-02-26T18:07:45.164601Z",
     "shell.execute_reply.started": "2025-02-26T18:07:45.158476Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_story(keywords):\n",
    "    prompt = f\"<|keywords|>{keywords}<|story|>\"\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=300,\n",
    "        do_sample=True,\n",
    "        temperature=0.9,\n",
    "        top_p=0.92,\n",
    "        repetition_penalty=1.2,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    story = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "    story = story.split(\"<|story|>\")[1].replace(\"<|endoftext|>\", \"\").strip()\n",
    "    return story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T18:07:46.841571Z",
     "iopub.status.busy": "2025-02-26T18:07:46.840618Z",
     "iopub.status.idle": "2025-02-26T18:07:50.900521Z",
     "shell.execute_reply": "2025-02-26T18:07:50.899559Z",
     "shell.execute_reply.started": "2025-02-26T18:07:46.841520Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"One day a little girl named Lily found a needle in her room. She was very stubborn and didn't know how to do it herself. So she decided not go near the needle.   But one day, she found something special: a tiny button on her shirt! It was shiny and soft and pretty. She loved the button so much that she would never want anyone else to see it.   And from then on, she always did what her mom said. She just wanted to be brave and share her favorite thing with everyone.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_story(\"day, girl, named, Lily, found, needle, room, knew, play, wanted, share, mom, sew, button, shirt, went\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T18:08:47.091244Z",
     "iopub.status.busy": "2025-02-26T18:08:47.090927Z",
     "iopub.status.idle": "2025-02-26T18:08:56.424008Z",
     "shell.execute_reply": "2025-02-26T18:08:56.422530Z",
     "shell.execute_reply.started": "2025-02-26T18:08:47.091216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Bob, Lily, brother, sister, daydreaming about, going, safari, excited, see, said, bring, mom, dad, went, arrived, saw, lotion, plants, looked, touched, skin, smiled, felt, happy, helped  , followed, house, got, took, care, cleaned, dried and dressed. Inside the secret cave, there was a lotion. It was very strong and smelled good. All of it was dirty.  The party was over so the kids could go home. They were all excited to visit them because they had never been here before! But when it finally came time for them to go, the mummy and dad were not sure what else to do.  They hurried outside and when they arrived at their safari, everybody was amazed! Everything in sight looked beautiful and warm, just like the lotion that had helped them with everything.  Finally after a while, the friends were able come back inside. They were safe, but they also had some pretty lotion too. It was soft and smelled nice.  And then, the treasure started pouring out of the surprise container into something even more special. Everyone loved it and they laughed and smiled as they felt so proud and happy.   The lotsicle gave them new power and helped them look better every day.\n"
     ]
    }
   ],
   "source": [
    "keywords = \"Moonlight Secret Journey Treasure Whisper Forest Shadow Magic Mystery Adventure\"\n",
    "print(generate_story(keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T18:08:58.397169Z",
     "iopub.status.busy": "2025-02-26T18:08:58.396414Z",
     "iopub.status.idle": "2025-02-26T18:09:03.950458Z",
     "shell.execute_reply": "2025-02-26T18:09:03.949476Z",
     "shell.execute_reply.started": "2025-02-26T18:08:58.397135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon every once in awhile there was an orange dragon. The dragon was very big and it was ready to fight!  One day the dragon was so strong that it could almost fight off all of its own. Everyone around it was amazed by how powerful the purple dragon was.  But then one day it found out that it had been warned about being too brave with its magic. The dragon's strength wasn't enough for it but it still wanted to be safe and close away from all the other dragons.  So the dragon decided to try again. This time it felt more confident than ever before. It didnÃ¢â‚¬â„¢t want any more dragons to fight against it anymore.  And just like that, the dragon learned that sometimes you have to be brave and never give up on what you do best.\n"
     ]
    }
   ],
   "source": [
    "keywords = \"Once upon a time, wand, danger dragon , black castle\"\n",
    "print(generate_story(keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T18:09:08.362512Z",
     "iopub.status.busy": "2025-02-26T18:09:08.362180Z",
     "iopub.status.idle": "2025-02-26T18:09:13.250863Z",
     "shell.execute_reply": "2025-02-26T18:09:13.249967Z",
     "shell.execute_reply.started": "2025-02-26T18:09:08.362482Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One day a little girl named Lily found a needle in her room. She knew it would be fun to play with. She wanted to share the needle with her mom.  So, Lily and her mom went to sew a button on her shirt. They were very careful with their sewing. They also had some small button on their shirt that they could wear together.  When they went home from sewing, Lily and her mom put the needle on her shirt. They did a good job sewing the button. And they all looked very cozy inside. From then On, they always made sure not to sew too many buttons because they thought it would be fun for them every day!'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = \"day, girl, named, Lily, found, needle, room, knew, play, wanted, share, mom, sew, button, shirt, went\"\n",
    "generate_story(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T18:09:14.125919Z",
     "iopub.status.busy": "2025-02-26T18:09:14.125345Z",
     "iopub.status.idle": "2025-02-26T18:09:16.082953Z",
     "shell.execute_reply": "2025-02-26T18:09:16.082107Z",
     "shell.execute_reply.started": "2025-02-26T18:09:14.125867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A brave new alien drifts away into space, staring back at his ruined city. He is always looking to uncover more secrets as he slowly dusts off the book, and the map reveals a large hidden secret underground where the strongest and most powerful humans have been found!\n"
     ]
    }
   ],
   "source": [
    "keywords = \"An astronaut drifts alone in space, staring at the ruins of an ancient civilization on a forgotten planet, A detective dusts off an old book, revealing a hidden map that could expose a powerful secret society, A lone robot wanders through an abandoned city, searching for signs of the last human survivor\"\n",
    "print(generate_story(keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T18:09:20.298329Z",
     "iopub.status.busy": "2025-02-26T18:09:20.297998Z",
     "iopub.status.idle": "2025-02-26T18:09:23.206778Z",
     "shell.execute_reply": "2025-02-26T18:09:23.205937Z",
     "shell.execute_reply.started": "2025-02-26T18:09:20.298299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forensic team has a unique arocutus. Every child have it! The team is very fast and strong! Everyone in the team is so patient and patient with their arocuts every day.  The teams are always together. The children are great at playing together and the arocutuses are special to them too. The team is like a powerful magic team that can do anything they set their mind to.\n"
     ]
    }
   ],
   "source": [
    "keywords = \"forensic team, airoplan in sky, child are playing\"\n",
    "print(generate_story(keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T18:09:29.664972Z",
     "iopub.status.busy": "2025-02-26T18:09:29.664577Z",
     "iopub.status.idle": "2025-02-26T18:09:56.379014Z",
     "shell.execute_reply": "2025-02-26T18:09:56.378024Z",
     "shell.execute_reply.started": "2025-02-26T18:09:29.664938Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: kaggle/working/fine_tuned_gpt2/ (stored 0%)\n",
      "  adding: kaggle/working/fine_tuned_gpt2/tokenizer_config.json (deflated 71%)\n",
      "  adding: kaggle/working/fine_tuned_gpt2/merges.txt (deflated 53%)\n",
      "  adding: kaggle/working/fine_tuned_gpt2/config.json (deflated 51%)\n",
      "  adding: kaggle/working/fine_tuned_gpt2/added_tokens.json (deflated 20%)\n",
      "  adding: kaggle/working/fine_tuned_gpt2/vocab.json (deflated 68%)\n",
      "  adding: kaggle/working/fine_tuned_gpt2/model.safetensors (deflated 7%)\n",
      "  adding: kaggle/working/fine_tuned_gpt2/special_tokens_map.json (deflated 81%)\n",
      "  adding: kaggle/working/fine_tuned_gpt2/generation_config.json (deflated 24%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r file_tuned_gpt2.zip '/kaggle/working/fine_tuned_gpt2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6304573,
     "sourceId": 10202111,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6595189,
     "sourceId": 10650878,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
