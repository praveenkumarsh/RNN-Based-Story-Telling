{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T21:44:58.853703Z",
     "iopub.status.busy": "2025-02-04T21:44:58.853327Z",
     "iopub.status.idle": "2025-02-04T21:45:13.963260Z",
     "shell.execute_reply": "2025-02-04T21:45:13.962082Z",
     "shell.execute_reply.started": "2025-02-04T21:44:58.853672Z"
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "!curl -L -o /kaggle/working/tinystories-narrative-classification.zip https://www.kaggle.com/api/v1/datasets/download/thedevastator/tinystories-narrative-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T21:45:13.964922Z",
     "iopub.status.busy": "2025-02-04T21:45:13.964620Z",
     "iopub.status.idle": "2025-02-04T21:45:33.231360Z",
     "shell.execute_reply": "2025-02-04T21:45:33.230288Z",
     "shell.execute_reply.started": "2025-02-04T21:45:13.964894Z"
    }
   },
   "outputs": [],
   "source": [
    "!unzip /kaggle/working/tinystories-narrative-classification.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:41:05.920088Z",
     "iopub.status.busy": "2025-02-02T20:41:05.919708Z",
     "iopub.status.idle": "2025-02-02T20:41:05.923764Z",
     "shell.execute_reply": "2025-02-02T20:41:05.922789Z",
     "shell.execute_reply.started": "2025-02-02T20:41:05.920053Z"
    }
   },
   "source": [
    "## Setting up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T21:45:33.233479Z",
     "iopub.status.busy": "2025-02-04T21:45:33.233162Z",
     "iopub.status.idle": "2025-02-04T21:45:57.424519Z",
     "shell.execute_reply": "2025-02-04T21:45:57.423444Z",
     "shell.execute_reply.started": "2025-02-04T21:45:33.233454Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "csv_data = pd.read_csv(\"train.csv\")\n",
    "csv_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T21:45:57.426293Z",
     "iopub.status.busy": "2025-02-04T21:45:57.425979Z",
     "iopub.status.idle": "2025-02-04T21:45:57.432718Z",
     "shell.execute_reply": "2025-02-04T21:45:57.431646Z",
     "shell.execute_reply.started": "2025-02-04T21:45:57.426267Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Open the CSV file\n",
    "with open('/kaggle/working/train.csv', \"r\") as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    \n",
    "    # Iterate through the rows\n",
    "    for i, row in enumerate(csv_reader):\n",
    "        if i == 1:  # Index 1 corresponds to the second row (0-based indexing)\n",
    "            print(row)\n",
    "            break  # Exit after printing the second row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T21:45:57.434293Z",
     "iopub.status.busy": "2025-02-04T21:45:57.433892Z",
     "iopub.status.idle": "2025-02-04T21:46:03.009423Z",
     "shell.execute_reply": "2025-02-04T21:46:03.004876Z",
     "shell.execute_reply.started": "2025-02-04T21:45:57.434258Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T21:46:03.015769Z",
     "iopub.status.busy": "2025-02-04T21:46:03.014785Z",
     "iopub.status.idle": "2025-02-04T21:46:05.062817Z",
     "shell.execute_reply": "2025-02-04T21:46:05.061824Z",
     "shell.execute_reply.started": "2025-02-04T21:46:03.015614Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T21:46:05.064454Z",
     "iopub.status.busy": "2025-02-04T21:46:05.063963Z",
     "iopub.status.idle": "2025-02-04T21:46:21.740530Z",
     "shell.execute_reply": "2025-02-04T21:46:21.738926Z",
     "shell.execute_reply.started": "2025-02-04T21:46:05.064415Z"
    }
   },
   "outputs": [],
   "source": [
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T21:46:21.744380Z",
     "iopub.status.busy": "2025-02-04T21:46:21.744026Z",
     "iopub.status.idle": "2025-02-04T21:46:22.420998Z",
     "shell.execute_reply": "2025-02-04T21:46:22.419582Z",
     "shell.execute_reply.started": "2025-02-04T21:46:21.744349Z"
    }
   },
   "outputs": [],
   "source": [
    "!rm /kaggle/working/output_story_dataset1.txt.gz\n",
    "!rm /kaggle/working/output_story_dataset2.txt.gz\n",
    "!rm /kaggle/working/story_dataset.txt.gz\n",
    "!rm /kaggle/working/tinystories-narrative-classification.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset which can be understand to be trained by GPT2 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T16:19:05.815149Z",
     "iopub.status.busy": "2025-02-05T16:19:05.814736Z",
     "iopub.status.idle": "2025-02-05T16:19:14.455419Z",
     "shell.execute_reply": "2025-02-05T16:19:14.453868Z",
     "shell.execute_reply.started": "2025-02-05T16:19:05.815113Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import spacy\n",
    "import gzip\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import download\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T16:19:14.457755Z",
     "iopub.status.busy": "2025-02-05T16:19:14.457068Z",
     "iopub.status.idle": "2025-02-05T16:19:15.640601Z",
     "shell.execute_reply": "2025-02-05T16:19:15.639103Z",
     "shell.execute_reply.started": "2025-02-05T16:19:14.457708Z"
    }
   },
   "outputs": [],
   "source": [
    "# Download NLTK resources\n",
    "download('stopwords')\n",
    "download('punkt')\n",
    "\n",
    "# Load spaCy model for advanced NLP\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T16:19:15.642740Z",
     "iopub.status.busy": "2025-02-05T16:19:15.642318Z",
     "iopub.status.idle": "2025-02-05T16:19:15.655893Z",
     "shell.execute_reply": "2025-02-05T16:19:15.654359Z",
     "shell.execute_reply.started": "2025-02-05T16:19:15.642701Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to extract keywords in order\n",
    "def extract_ordered_terms(text):\n",
    "    # Tokenize and clean the text\n",
    "    tokens = word_tokenize(re.sub(r'[^\\w\\s]', '', text.lower()))\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words and len(word) > 2]\n",
    "\n",
    "    # Process text with spaCy\n",
    "    doc = nlp(text)\n",
    "\n",
    "    terms = []\n",
    "    for token in doc:\n",
    "        if token.text.lower() in filtered_tokens:\n",
    "            if token.pos_ in {\"VERB\", \"NOUN\"}:  # Actions or objects\n",
    "                terms.append(token.text)\n",
    "        if token.ent_type_ in {\"GPE\", \"LOC\", \"PERSON\"}:  # Places or names\n",
    "            terms.append(token.text)\n",
    "        if token.text.lower() in {\"happy\", \"sad\", \"angry\", \"excited\", \"scared\", \"love\"}:  # Emotions\n",
    "            terms.append(token.text)\n",
    "\n",
    "    # Deduplicate while preserving order\n",
    "    seen = set()\n",
    "    ordered_terms = [term for term in terms if not (term in seen or seen.add(term))]\n",
    "    return ordered_terms\n",
    "\n",
    "# Function to process a single row\n",
    "def process_row(row):\n",
    "    story = row.strip().replace(\"\\n\", \" \")\n",
    "    if not story:\n",
    "        return None  # Skip empty stories\n",
    "\n",
    "    keywords = extract_ordered_terms(story)\n",
    "    formatted_story = (\n",
    "        f\"<|startoftext|>Keywords: {', '.join(keywords)}\\n\"\n",
    "        f\"Story: {story}<|endoftext|>\\n\"\n",
    "    )\n",
    "    return formatted_story\n",
    "\n",
    "# Function to process a batch of stories\n",
    "def process_batch(batch):\n",
    "    return [process_row(row) for row in batch if row]\n",
    "\n",
    "# Function to process the dataset in chunks with parallel processing\n",
    "def process_csv_in_chunks(input_file, output_file, chunksize=10000):\n",
    "    num_cores = cpu_count()\n",
    "    print(f\"Using {num_cores} CPU cores for parallel processing.\")\n",
    "\n",
    "    # Calculate total rows for live status updates\n",
    "    total_rows = sum(1 for _ in open(input_file)) - 1  # Subtract header row\n",
    "\n",
    "    processed_count = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    with gzip.open(output_file, \"wt\") as output:\n",
    "        for chunk_idx, chunk in enumerate(pd.read_csv(input_file, chunksize=chunksize)):\n",
    "            stories = chunk['text'].dropna().tolist()  # Ensure no null values\n",
    "\n",
    "            # Split stories into smaller batches for parallel processing\n",
    "            batches = [stories[i:i + chunksize // num_cores] for i in range(0, len(stories), chunksize // num_cores)]\n",
    "\n",
    "            with Pool(num_cores) as pool:\n",
    "                results = pool.map(process_batch, batches)\n",
    "\n",
    "            # Flatten the results and filter out None values\n",
    "            flat_results = [item for sublist in results for item in sublist if item]\n",
    "\n",
    "            # Write to output file\n",
    "            output.writelines(flat_results)\n",
    "\n",
    "            # Update progress\n",
    "            processed_count += len(stories)\n",
    "            elapsed_time = time.time() - start_time\n",
    "            percentage_complete = (processed_count / total_rows) * 100\n",
    "            print(f\"Chunk {chunk_idx + 1}: Processed {processed_count}/{total_rows} stories ({percentage_complete:.2f}%) in {elapsed_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T16:19:15.657781Z",
     "iopub.status.busy": "2025-02-05T16:19:15.657402Z",
     "iopub.status.idle": "2025-02-05T16:19:15.684560Z",
     "shell.execute_reply": "2025-02-05T16:19:15.683034Z",
     "shell.execute_reply.started": "2025-02-05T16:19:15.657749Z"
    }
   },
   "outputs": [],
   "source": [
    "# Main function to execute the process\n",
    "def main():\n",
    "    input_file = \"/kaggle/working/train.csv\"  \n",
    "    output_file = \"/kaggle/working/output_story_dataset2.txt.gz\" \n",
    "\n",
    "    print(\"Starting dataset processing...\")\n",
    "    process_csv_in_chunks(input_file, output_file)\n",
    "    print(\"Processing complete. Output saved to:\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-02-04T21:44:15.511Z"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
